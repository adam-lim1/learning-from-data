{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1\n",
    "Adam Lim, 4/21/19 <br></br>\n",
    "Exercises from the course Learning From Data: https://work.caltech.edu/homeworks.html\n",
    "<br></br>\n",
    "Homework 1 link: https://work.caltech.edu/homework/hw1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #1\n",
    "What types of Machine Learning, if any, best describe the following three scenarios:<br></br>\n",
    "- i. A coin classification system is created for a vending machine. The developers obtain exact coin specifications from the U.S. Mint and derive a statistical model of the size, weight, and denomination, which the vending machine then uses to classify coins.\n",
    "- ii. Instead of calling the U.S. Mint to obtain coin information, an algorithm is presented with a large set of labeled coins. The algorithm uses this data to infer decision boundaries which the vending machine then uses to classify its coins.\n",
    "- iii. A computer develops a strategy for playing Tic-Tac-Toe by playing repeatedly and adjusting its strategy by penalizing moves that eventually lead to losing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Answer </b> <br></br>\n",
    "[d] (i) Not learning, (ii) Supervised Learning, (iii) Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #2\n",
    "Which of the following problems are best suited for Machine Learning?\n",
    "- (i) Classifying numbers into primes and non-primes.\n",
    "- (ii) Detecting potential fraud in credit card charges.\n",
    "- (iii) Determining the time it would take a falling object to hit the ground.\n",
    "- (iv) Determining the optimal cycle for traffic lights in a busy intersection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Answer </b> <br></br>\n",
    "[a] (ii) and (iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #3\n",
    "We have 2 opaque bags, each containing 2 balls. One bag has 2 black balls and\n",
    "the other has a black ball and a white ball. You pick a bag at random and\n",
    "then pick one of the balls in that bag at random. When you look at the ball,\n",
    "it is black. You now pick the second ball from that same bag. What is the\n",
    "probability that this ball is also black?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Answer </b> <br></br>\n",
    "Bag 1 = [Black, Black] <br></br>\n",
    "Bag 2 = [Black, White] <br></br>\n",
    "\n",
    "Bayes Theorem: p(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "P(Ball 2 is Black | Ball 1 is Black) = p(Ball 1 is Black | Ball 2 is Black) * p(Ball 2 is black) / p(ball 1 is black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1* (0.5*0 + 0.5*1)) / (0.5*1 + 0.5*0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[d] 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #4\n",
    "Consider a sample of 10 marbles drawn from a bin containing red and green marbles.\n",
    "The probability that any marble we draw is red is µ = 0.55 (independently, with\n",
    "replacement). We address the probability of getting no red marbles (ν = 0) in the\n",
    "following cases:\n",
    "\n",
    "We draw only one such sample. Compute the probability that ν = 0. The\n",
    "closest answer is (‘closest answer’ means: |your answer−given option| is closest\n",
    "to 0):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Answer </b><br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003405062891601559"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of sample having no red marbles\n",
    "pow((1-0.55),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[b] 3.405 × (10 ^ −4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #5\n",
    "We draw 1,000 independent samples. Compute the probability that (at least)\n",
    "one of the samples has ν = 0. The closest answer is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer</b>\n",
    "- P(1+ samples having no red) = 1 - P(All samples having red marbles)\n",
    "- P(Sample having red marble) = 1 - P(Sample having no red marbles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996594937108398\n"
     ]
    }
   ],
   "source": [
    "# P(Sample having red marble) = 1 - P(Sample having no red marbles)\n",
    "p_red = 1 - pow((1-0.55),10)\n",
    "print(p_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28863119784980995"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(1+ samples having no red) = 1 - P(All samples having red marbles)\n",
    "1 - pow(p_red, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[c] 0.289"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #6\n",
    "Consider a Boolean target function over a 3-dimensional input space X = {0, 1}\n",
    "3\n",
    "(instead of our ±1 binary convention, we use 0,1 here since it is standard for Boolean\n",
    "functions). We are given a data set D of five examples represented in the table below,\n",
    "where yn = f(xn) for n = 1, 2, 3, 4, 5. <br></br>\n",
    "\n",
    "|   | Xn |   | Yn |\n",
    "|---|----|---|----|\n",
    "| 0 | 0  | 0 | 0  |\n",
    "| 0 | 0  | 1 | 1  |\n",
    "| 0 | 1  | 0 | 1  |\n",
    "| 0 | 1  | 1 | 0  |\n",
    "| 1 | 0  | 0 | 1  |\n",
    "\n",
    "\n",
    "Note that in this simple Boolean case, we can enumerate the entire input space (since\n",
    "there are only 2^3 = 8 distinct input vectors), and we can enumerate the set of all\n",
    "possible target functions (there are only 2^2^3 = 256 distinct Boolean function on 3 Boolean inputs). <br></br><br></br>\n",
    "Let us look at the problem of learning f. Since f is unknown except inside D, any\n",
    "function that agrees with D could conceivably be f. Since there are only 3 points in\n",
    "X outside D, there are only 2^3 = 8 such functions.\n",
    "The remaining points in X which are not in D are: 101, 110, and 111. We want to\n",
    "determine the hypothesis that agrees the most with the possible target functions. In\n",
    "order to quantify this, count how many of the 8 possible target functions agree with\n",
    "each hypothesis on all 3 points, how many agree on just 2 of the points, on just 1\n",
    "point, and how many do not agree on any points. The final score for each hypothesis\n",
    "is computed as follows:\n",
    "<br></br><br></br>\n",
    "Score = (# of target functions agreeing with hypothesis on all 3 points)×3 + (#\n",
    "of target functions agreeing with hypothesis on exactly 2 points)×2 + (# of target\n",
    "functions agreeing with hypothesis on exactly 1 point)×1 + (# of target functions\n",
    "agreeing with hypothesis on 0 points)×0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Answer </b>\n",
    "[e] They are all equivalent (equal scores for g in [a] through [d])\n",
    "\n",
    "| Xn    |   |   | A  | B  | C  | D  |\n",
    "|-------|---|---|----|----|----|----|\n",
    "| 0     | 0 | 0 | 0  | 3  | 3  | 0  |\n",
    "| 0     | 0 | 1 | 1  | 2  | 1  | 2  |\n",
    "| 0     | 1 | 0 | 1  | 2  | 1  | 2  |\n",
    "| 0     | 1 | 1 | 2  | 1  | 1  | 2  |\n",
    "| 1     | 0 | 0 | 1  | 2  | 1  | 2  |\n",
    "| 1     | 1 | 0 | 2  | 1  | 1  | 2  |\n",
    "| 1     | 1 | 1 | 3  | 0  | 3  | 0  |\n",
    "| 1     | 0 | 1 | 2  | 1  | 1  | 2  |\n",
    "| Total |   |   | 12 | 12 | 12 | 12 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions #7 - #10\n",
    "In this problem, you will create your own target function f and data set D to see\n",
    "how the Perceptron Learning Algorithm works. Take d = 2 so you can visualize the\n",
    "problem, and assume X = [−1, 1] × [−1, 1] with uniform probability of picking each\n",
    "x ∈ X . <br></br><br></br>\n",
    "In each run, choose a random line in the plane as your target function f (do this by\n",
    "taking two random, uniformly distributed points in [−1, 1] × [−1, 1] and taking the\n",
    "line passing through them), where one side of the line maps to +1 and the other maps\n",
    "to −1. Choose the inputs xn of the data set as random points (uniformly in X ), and\n",
    "evaluate the target function on each xn to get the corresponding output yn. <br></br><br></br>\n",
    "Now, in each run, use the Perceptron Learning Algorithm to find g. Start the PLA\n",
    "with the weight vector w being all zeros (consider sign(0) = 0, so all points are initially misclassified), and at each iteration have the algorithm choose a point randomly\n",
    "from the set of misclassified points. We are interested in two quantities: the number\n",
    "of iterations that PLA takes to converge to g, and the disagreement between f and\n",
    "g which is P[f(x) != g(x)] (the probability that f and g will disagree on their classification of a random point). You can either calculate this probability exactly, or\n",
    "approximate it by generating a sufficiently large, separate set of points to estimate it. <br></br><br></br>\n",
    "In order to get a reliable estimate for these two quantities, you should repeat the\n",
    "experiment for 1000 runs (each run as specified above) and take the average over\n",
    "these runs.<br></br>\n",
    "\n",
    "<b> Question #7: </b> Take N = 10. How many iterations does it take on average for the PLA to\n",
    "converge for N = 10 training points? Pick the value closest to your results\n",
    "(again, ‘closest’ means: |your answer − given option| is closest to 0). <br></br>\n",
    "\n",
    "<b> Question #8: </b> Which of the following is closest to P[f(x) != g(x)] for N = 10?\n",
    "\n",
    "<b>Question #9: </b> Now, try N = 100. How many iterations does it take on average for the PLA\n",
    "to converge for N = 100 training points? Pick the value closest to your results.<br></br>\n",
    "\n",
    "<b>Question #10: </b> Which of the following is closest to P[f(x) 6= g(x)] for N = 100?<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLine:\n",
    "    def __init__(self, pt1, pt2):\n",
    "        self.pt1 = pt1\n",
    "        self.pt2 = pt2\n",
    "        self.slope = (pt1[1] - pt2[1]) / (pt1[0] - pt2[0])\n",
    "        # y - y1 = m(x - x1) -> y = mx - mx1 + y1 \n",
    "        self.intercept = self.slope * (-1 * pt1[0]) + pt1[1]\n",
    "    \n",
    "    def evaluate_pt(self, random_pt):\n",
    "        # Evaluate if point is above or below line\n",
    "        line_pt = random_pt[0]*self.slope + self.intercept\n",
    "        if random_pt[1] > line_pt:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize DF of N random points evaluated on specified random line\n",
    "def PointsDF(N, line):\n",
    "    pts_df = pd.DataFrame(np.random.uniform(-1,1,size=(N,2)))\n",
    "    pts_df['x_vector'] = list(zip(np.ones(pts_df.shape[0]), pts_df[0], pts_df[1]))\n",
    "    pts_df['x_vector'] = pts_df['x_vector'].apply(lambda x: np.asarray(x))\n",
    "    pts_df['y_initial'] = pts_df['x_vector'].apply(lambda x: line.evaluate_pt(x[1:]))\n",
    "    return pts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate using Perceptron Learning Algorithm\n",
    "def converge(pts_df, N, f):\n",
    "    weights = np.zeros(3) # Initialize vector of weights\n",
    "    iters = 0\n",
    "\n",
    "    pts_df['evaluate'] = pts_df['x_vector'].apply(lambda x: np.sign(np.dot(weights, x)))\n",
    "    pts_df['match'] = np.where(pts_df.y_initial == pts_df.evaluate, 1, -1)\n",
    "    matches = pts_df['match'].sum()\n",
    "    \n",
    "    while matches != N: # While 1+ misclassified points\n",
    "        iters = iters + 1\n",
    "        \n",
    "        # Use misclassified to update weights vector\n",
    "        temp = pts_df.query('match != 1').sample(1)\n",
    "        weights = weights + temp['y_initial'].values[0]* temp['x_vector'].values[0]\n",
    "        print(\"Iter {} : {}\".format(iters, weights), file=f)\n",
    "\n",
    "        pts_df['evaluate'] = pts_df['x_vector'].apply(lambda x: np.sign(np.dot(weights, x)))\n",
    "        pts_df['match'] = np.where(pts_df.y_initial == pts_df.evaluate, 1, -1)\n",
    "        matches = pts_df['match'].sum()\n",
    "\n",
    "    print('Converged at Iteration {}'.format(iters), file=f)\n",
    "    return iters, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "OOS_N = 1000\n",
    "\n",
    "iters_list = []\n",
    "probability_list = []\n",
    "\n",
    "with open(\"HW1_output.txt\", \"a\") as f:\n",
    "    print('################## QUESTIONS 7 - 8 ##################', file=f)\n",
    "    for i in range(0,1000):\n",
    "        print('***************** TRIAL {} *****************'.format(i), file=f)\n",
    "\n",
    "        # Initialize Random Points and Line\n",
    "        line = RandomLine(np.random.uniform(-1,1, 2), np.random.uniform(-1,1, 2))\n",
    "        pts_df = PointsDF(N, line)\n",
    "\n",
    "        # Execute PLA\n",
    "        iters, weights = converge(pts_df, N, f)\n",
    "\n",
    "        # Evaluate Predictive ability on Out of Sample dataset\n",
    "        OOS = PointsDF(OOS_N, line)\n",
    "        OOS['Predict'] = OOS['x_vector'].apply(lambda x: np.sign(np.dot(weights, x)))\n",
    "        OOS['Correct'] = np.where(OOS.Predict == OOS.y_initial, 1, 0)\n",
    "        OOS_correct_rate = OOS['Correct'].sum() / OOS['Correct'].count()\n",
    "        print(OOS_correct_rate, file=f)\n",
    "        iters_list.append(iters)\n",
    "        probability_list.append(OOS_correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.103\n",
      "0.8894070000000001\n"
     ]
    }
   ],
   "source": [
    "# Average number of iterations to converge\n",
    "print(sum(iters_list)/len(iters_list))\n",
    "\n",
    "# Average probability f(x) = g(x) in Out of Sample DF\n",
    "print(sum(probability_list)/len(probability_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Answer (7) </b> <br></br>\n",
    "[b] 15\n",
    "\n",
    "<b> Answer (8) </b> <br></br>\n",
    "[c] 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "OOS_N = 1000\n",
    "\n",
    "iters_list = []\n",
    "probability_list = []\n",
    "\n",
    "with open(\"HW1_output.txt\", \"a\") as f:\n",
    "    print('################## QUESTIONS 9 - 10 ##################', file=f)\n",
    "    for i in range(0,1000):\n",
    "        print('***************** TRIAL {} *****************'.format(i), file=f)\n",
    "\n",
    "        # Initialize Random Points and Line\n",
    "        line = RandomLine(np.random.uniform(-1,1, 2), np.random.uniform(-1,1, 2))\n",
    "        pts_df = PointsDF(N, line)\n",
    "\n",
    "        # Execute PLA\n",
    "        iters, weights = converge(pts_df, N, f)\n",
    "\n",
    "        # Evaluate Predictive ability on Out of Sample dataset\n",
    "        OOS = PointsDF(OOS_N, line)\n",
    "        OOS['Predict'] = OOS['x_vector'].apply(lambda x: np.sign(np.dot(weights, x)))\n",
    "        OOS['Correct'] = np.where(OOS.Predict == OOS.y_initial, 1, 0)\n",
    "        OOS_correct_rate = OOS['Correct'].sum() / OOS['Correct'].count()\n",
    "        print(OOS_correct_rate, file=f)\n",
    "        iters_list.append(iters)\n",
    "        probability_list.append(OOS_correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.556\n",
      "0.9866660000000032\n"
     ]
    }
   ],
   "source": [
    "# Average number of iterations to converge\n",
    "print(sum(iters_list)/len(iters_list))\n",
    "\n",
    "# Average probability f(x) = g(x) in Out of Sample DF\n",
    "print(sum(probability_list)/len(probability_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Answer (8) </b><br></br>\n",
    "[b] 100\n",
    "\n",
    "<b> Answer (10) </b><br></br>\n",
    "[b] 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
